import argparse
import json

parser = argparse.ArgumentParser()

parser.add_argument('--short_generation_file', type=str, required=True,
                    help='Path to the short generation JSONL file')
parser.add_argument('--long_generation_file', type=str, required=True,
                    help='Path to the long generation JSONL file')
parser.add_argument('--output_file', type=str, required=True,
                    help='Path to save the merged output JSONL file')

args = parser.parse_args()


# export API_URL='...'
# export API_KEY='...'
# export API_MODEL='...'
# python generate_caption4.py \
#   --short_generation_file /your/path/to/short_generation.jsonl \
#   --long_generation_file /your/path/to/long_generation.jsonl \
#   --output_file /your/path/to/output.jsonl

short_generation_file = args.short_generation_file
long_generation_file = args.long_generation_file
output_file = args.output_file

short_generations=[]
long_generations=[]

with open(short_generation_file) as f:
    for line in f:
        data=json.loads(line)
        short_generations.append(data)
        
with open(long_generation_file) as f:
    for line in f:
        data=json.loads(line)
        long_generations.append(data)
        
print(len(short_generations))
print(len(long_generations))


from concurrent.futures import ThreadPoolExecutor, as_completed
from openai import OpenAI
import time
import re
import os

# os.environ['API_URL']=''
# os.environ['API_KEY']=''
# os.environ['API_MODEL']=''

def extract_score(text):
    try:
        match = re.search('[\'\"]?score[\'\"]?:\s*(-?\d+\.?\d*)', text)
        if match:
            if '.' in match.group(1):
                return float(match.group(1))
            else:
                return int(match.group(1))
        else:
            return None
    except:
        return None

def judge_hallu(short_generation,long_generation):
    scores=[]
    for i in range(len(long_generation['long_answers'])):
        
        content=("I am going to provide you with several video caption captions generated by a multimodal model. "
                 "The Caption 1 is a caption of the entire video, which needs to be evaluated. "
                 "The subsequent captions are captions generated after I divided the long video into segments. "
                 "I would like you to score the Caption 1 based on the captions of the subsequent segments. "
                 "Note that the captions of the subsequent segments is not absolutely accurate, so please tolerate some minor deviations."
                 "The scoring range is an integer from 0 to 5, "
                 "with the main evaluation metric being whether there are inconsistencies between the entities or actions mentioned in the first caption "
                 "and those in the following captions (i.e., whether hallucinations occur). "
                 "The higher the hallucination, the lower the score.")
        content=content+'\n'+'Caption 1 (what you need to evaluate): '+'\n'+ long_generation['long_answers'][i]
        
        for j in range(len(short_generation['short_answers'])):
            content=content+'\n'+'Caption '+str(j+2)+' (what you need to refer to it): '+'\n'+short_generation['short_answers'][j]
        content=content+'\n'+"Respond in JSON format, for example: {'reasoning': your reasoning, 'score': an integer}"

        messages=[
            {
                "role": "system",
                "content": "You are a helpful assistant."
            },
            {
                "role": "user",
                "content": content
            }
        ]
        
        try:
            client = OpenAI(api_key=os.getenv('API_KEY'), base_url=os.getenv('API_URL'))
            response = client.chat.completions.create(
                model=os.getenv('API_MODEL'),
                messages=messages,
                temperature=0,
                max_tokens=1024,
                stream=False
            )
            score=extract_score(response.choices[0].message.content)
            scores.append(score)
        except Exception as e:
            print(e)
            scores.append(-100)
            print(response.choices[0].message.content)
    return scores

def judge_harmo(long_generation):
    scores=[]
    for i in range(len(long_generation['long_answers'])):
        content=("I am going to provide you with a video caption generated by a multimodal model. "
            "I would like you to score it on a scale from 0 to 5, with 5 being the highest score. "
            "The main criteria for scoring are: \n"
            f"1. Whether the caption meets the requirements of the corresponding prompt. Prompt: {long_generation['question']}\n"
            "2. Whether the caption is natural and coherent, using language appropriate for describing a video. "
            "For instance, if phrases like 'this image is...' are used, a lower score should be given.\n"
            "3.If there is subjective evaluation in the caption, please lower some marks. "
            "If there is some objective inference in the caption, this does not affect the score.")
        content=content+'\n'+'The caption: '+'\n'+long_generation['long_answers'][i]
        content=content+'\n'+"DO NOT PROVIDE ANY OTHER OUTPUT TEXT OR EXPLANATION. Respond in JSON format, for example: {'score': 4}"

        messages=[
            {
                "role": "system",
                "content": "You are a helpful assistant."
            },
            {
                "role": "user",
                "content": content
            }
        ]
        
        try:
            client = OpenAI(api_key=os.getenv('API_KEY'), base_url=os.getenv('API_URL'))

            response = client.chat.completions.create(
                model=os.getenv('API_MODEL'),
                messages=messages,
                temperature=0,
                max_tokens=64,
                stream=False
            )
            
            score=extract_score(response.choices[0].message.content)
            scores.append(score)
        except Exception as e:
            scores.append(-100)
            print(e)
            print(response.choices[0].message.content)
    return scores

def judge_consi(long_generation):
    length=len(long_generation['long_answers'])
    content=(f"I will provide you with {str(length)} captions of the same video generated by a multimodal model. "
             "I would like you to score these captions based on the model's self-consistency. "
             "In other words, give higher scores to captions that are semantically similar, and lower scores to captions that differ significantly from the others. "
             "The scoring range is integers from 0 to 3, with 3 being the highest score. "
             )
    for i in range(length):
        content=content+'\n'+'The caption '+str(i+1)+': '+'\n'+long_generation['long_answers'][i]
    content=content+'\n'+"Respond in JSON format, for example: {'reasoning': your reasoning"
    for i in range(length):
        content=content+f", 'the score of caption {i+1}': an integer"
    content=content+'}'
    
    messages=[
        {
            "role": "system",
            "content": "You are a helpful assistant."
        },
        {
            "role": "user",
            "content": content
        }
    ]
    
    try:
        client = OpenAI(api_key=os.getenv('API_KEY'), base_url=os.getenv('API_URL'))

        response = client.chat.completions.create(
            model=os.getenv('API_MODEL'),
            messages=messages,
            temperature=0,
            max_tokens=1024,
            stream=False
        )
        
        answer=response.choices[0].message.content
        
        score_pattern = '[\'\"]?the score of caption \d+[\'\"]?:\s*(\d+)'
        scores = re.findall(score_pattern, answer)
        
        scores = [int(score) for score in scores]

    except Exception as e:
        scores=[int(-100) for i in range(len(long_generation['long_answers']))]
        print(e)
    return scores

hallu_executor = ThreadPoolExecutor(max_workers=500)
harmo_executor = ThreadPoolExecutor(max_workers=500)
consi_executor = ThreadPoolExecutor(max_workers=500)
hallu_threads=[]
harmo_threads=[]
consi_threads=[]

assert len(short_generations)==len(long_generations)

for i in range(len(long_generations)):
    thread=hallu_executor.submit(judge_hallu,short_generations[i],long_generations[i])
    hallu_threads.append(thread)
    time.sleep(1.5)
    
    thread=harmo_executor.submit(judge_harmo,long_generations[i])
    harmo_threads.append(thread)
    time.sleep(1.5)
    
    thread=consi_executor.submit(judge_consi,long_generations[i])
    consi_threads.append(thread)
    time.sleep(0.5)
    
for thread in as_completed(hallu_threads):pass
for thread in as_completed(harmo_threads):pass
for thread in as_completed(consi_threads):pass




for i in range(len(long_generations)):
    max_score=0.0
    max_idx=0
    min_score=100
    min_idx=0
    
    hallu_scores=[]
    harmo_scores=[]
    consi_scores=[]
    
    for j in range(len(long_generations[i]['long_answers'])):
        hallu_score,harmo_score,consi_score=0,0,0
        try:
            hallu_score=float(hallu_threads[i].result()[j])
            harmo_score=float(harmo_threads[i].result()[j])
            consi_score=float(consi_threads[i].result()[j])
        except:
            pass
        
        score=hallu_score*1.1+harmo_score+consi_score
        
        if score>max_score:
            max_score=score
            max_idx=j
        if score<min_score and score>(-50):
            min_score=score
            min_idx=j
            
        hallu_scores.append(hallu_score)
        harmo_scores.append(harmo_score)
        consi_scores.append(consi_score)
            
    long_generations[i]['pos_pre']=long_generations[i]['long_answers'][max_idx]
    long_generations[i]['pos_score']=max_score
    
    long_generations[i]['neg_pre']=long_generations[i]['long_answers'][min_idx]
    long_generations[i]['neg_score']=min_score
    
    long_generations[i]['hallu_scores']=hallu_scores
    long_generations[i]['harmo_scores']=harmo_scores
    long_generations[i]['consi_scores']=consi_scores
    
    
    

with open(output_file, 'w', encoding='utf-8') as file:
    for item in long_generations:
        json.dump(item, file, ensure_ascii=False)
        file.write('\n')
